{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/roger/Machine_Learning_Immunogenicity/src')\n",
    "import onehot\n",
    "from gzip import GzipFile\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/roger/Machine_Learning_Immunogenicity'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278230, 27)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcell_all=pd.read_table(\"/home/roger/other/Machine_Learning_Immunogenicity/data/tcell.txt.gz\",compression='gzip')\n",
    "tcell_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tcell_comp=pd.read_table('/home/roger/other/Machine_Learning_Immunogenicity/data/tcell_peptide_allele_nodups.txt.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77970, 3)\n"
     ]
    }
   ],
   "source": [
    "print tcell_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Allele Name</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLEDLERDL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IEQQADNMITEMLQK</td>\n",
       "      <td>H2-IAk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGEGWPYIACRTSVVGRAWE</td>\n",
       "      <td>H2-IAb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRVAFAGL</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVAKAGKPL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMLQDIATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMLRGVNVL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAVEELKAL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VEGEALATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEWPTFNVGW</td>\n",
       "      <td>HLA-B*44:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Description  Allele Name  bin\n",
       "0             KLEDLERDL  HLA-A*02:01    1\n",
       "1       IEQQADNMITEMLQK       H2-IAk    1\n",
       "2  SGEGWPYIACRTSVVGRAWE       H2-IAb    1\n",
       "3              TRVAFAGL        H2-Kb    1\n",
       "4             AVAKAGKPL  HLA-E*01:01    1\n",
       "5             AMLQDIATL  HLA-E*01:01    1\n",
       "6             KMLRGVNVL  HLA-E*01:01    1\n",
       "7             AAVEELKAL  HLA-E*01:01    0\n",
       "8             VEGEALATL  HLA-E*01:01    0\n",
       "9            AEWPTFNVGW  HLA-B*44:03    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcell_comp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 15,\n",
       " 20,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 15,\n",
       " 14,\n",
       " 10,\n",
       " 11,\n",
       " 20,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 12,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 20,\n",
       " 15,\n",
       " 15,\n",
       " 23,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 23,\n",
       " 15,\n",
       " 15,\n",
       " 23,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 23,\n",
       " 20,\n",
       " 20,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 20,\n",
       " 10,\n",
       " 18,\n",
       " 39,\n",
       " 39,\n",
       " 14,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 16,\n",
       " 31,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 23,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 20,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 16,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 30,\n",
       " 22,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 25,\n",
       " 20,\n",
       " 20,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 22,\n",
       " 20,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 24,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 17,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 10,\n",
       " 18,\n",
       " 9,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 19,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 17,\n",
       " 18,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 16,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 19,\n",
       " 15,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 15,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 14,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 36,\n",
       " 15,\n",
       " 15,\n",
       " 18,\n",
       " 10,\n",
       " 20,\n",
       " 24,\n",
       " 25,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 18,\n",
       " 12,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 18,\n",
       " 24,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 16,\n",
       " 18,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 7,\n",
       " 20,\n",
       " 23,\n",
       " 17,\n",
       " 9,\n",
       " 35,\n",
       " 43,\n",
       " 32,\n",
       " 40,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 20,\n",
       " 20,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 20,\n",
       " 40,\n",
       " 40,\n",
       " 29,\n",
       " 23,\n",
       " 36,\n",
       " 25,\n",
       " 22,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 9,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 20,\n",
       " 9,\n",
       " 20,\n",
       " 8,\n",
       " 9,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 15,\n",
       " 9,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 17,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 20,\n",
       " 13,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 19,\n",
       " 9,\n",
       " 16,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(len,tcell_comp['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  141, 22314, 44689,  9370,   695,   485,   113,    70,    51,\n",
      "          30,    10,     1,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     1]), array([   3.        ,    7.56666667,   12.13333333,   16.7       ,\n",
      "         21.26666667,   25.83333333,   30.4       ,   34.96666667,\n",
      "         39.53333333,   44.1       ,   48.66666667,   53.23333333,\n",
      "         57.8       ,   62.36666667,   66.93333333,   71.5       ,\n",
      "         76.06666667,   80.63333333,   85.2       ,   89.76666667,\n",
      "         94.33333333,   98.9       ,  103.46666667,  108.03333333,\n",
      "        112.6       ,  117.16666667,  121.73333333,  126.3       ,\n",
      "        130.86666667,  135.43333333,  140.        ]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6SCWPqSVJD/B5HvRai07gstAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4fa3b5950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76134\n"
     ]
    }
   ],
   "source": [
    "print np.histogram(map(len,tcell_comp['Description']),bins=30)\n",
    "plt.hist(np.histogram(map(len,tcell_comp['Description']),bins=30))\n",
    "plt.show()\n",
    "print np.sum(np.asarray(map(len,tcell_comp['Description'])) <= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44524, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Allele Name</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLEDLERDL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IEQQADNMITEMLQK</td>\n",
       "      <td>H2-IAk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGEGWPYIACRTSVVGRAWE</td>\n",
       "      <td>H2-IAb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRVAFAGL</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVAKAGKPL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMLQDIATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMLRGVNVL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAVEELKAL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VEGEALATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEWPTFNVGW</td>\n",
       "      <td>HLA-B*44:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>APIWPYEILY</td>\n",
       "      <td>HLA-B*35:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VPYVNVAPSSSWTQH</td>\n",
       "      <td>H2-b class I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YSNQYQNSIDLSAS</td>\n",
       "      <td>H2-b class I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LLCPAGINAV</td>\n",
       "      <td>HLA-A2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FLFDGSPTYVL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LTILVALALFLLAAHASARQ</td>\n",
       "      <td>HLA-class II</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FVFLRNFSL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ALENKRKQL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QLAAGGKHL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RTAGPSVGGV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GGFVPNMLSV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FLFLRNFSL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FPPSPLFFFL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SYVPSAEQIL</td>\n",
       "      <td>H2-Kd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GASPAVSSL</td>\n",
       "      <td>HLA-class I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FLPSPLFFFL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CMTWNQMNL</td>\n",
       "      <td>HLA-A*24:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CYTWNQMNL</td>\n",
       "      <td>HLA-A*24:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IPGVAYTSPEVAWVG</td>\n",
       "      <td>H2-d class I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EEASSTRGNLDVAKLNGDWF</td>\n",
       "      <td>HLA-class II</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77940</th>\n",
       "      <td>PFVKIVEHHTLMTTH</td>\n",
       "      <td>H2-IEd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77941</th>\n",
       "      <td>TYWCYITEL</td>\n",
       "      <td>H2-Kd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77942</th>\n",
       "      <td>SYNSVKEII</td>\n",
       "      <td>H2-Kd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77943</th>\n",
       "      <td>AVKNYCSKL</td>\n",
       "      <td>H2-Db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77944</th>\n",
       "      <td>SNPTYSVM</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77945</th>\n",
       "      <td>MGVANLDNL</td>\n",
       "      <td>H2-Db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77946</th>\n",
       "      <td>SIINFEHL</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77947</th>\n",
       "      <td>IVLGLIATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77948</th>\n",
       "      <td>KVLGLWATV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77949</th>\n",
       "      <td>LQLCCLATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77950</th>\n",
       "      <td>RGTPMVITV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77951</th>\n",
       "      <td>KLNPMLAKA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77952</th>\n",
       "      <td>RDVPMLITT</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77953</th>\n",
       "      <td>LALPMPATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77954</th>\n",
       "      <td>NDFCCVATV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77955</th>\n",
       "      <td>RINAILATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77956</th>\n",
       "      <td>GGNGMLATI</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77957</th>\n",
       "      <td>KDLVLLATI</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77958</th>\n",
       "      <td>RLNTVLATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77959</th>\n",
       "      <td>MGLPGVATV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77960</th>\n",
       "      <td>LVLPILITI</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77961</th>\n",
       "      <td>RVNRLIIWV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77962</th>\n",
       "      <td>SGDGLVATG</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77963</th>\n",
       "      <td>MGNGCLRIV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77964</th>\n",
       "      <td>NGVRVLATA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77965</th>\n",
       "      <td>MINPLVITT</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77966</th>\n",
       "      <td>NIVCPLCTL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77967</th>\n",
       "      <td>ITNCLLSTA</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77968</th>\n",
       "      <td>KAVYNLATM</td>\n",
       "      <td>H2-Db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77969</th>\n",
       "      <td>KAVCNFATM</td>\n",
       "      <td>H2-Db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44524 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Description   Allele Name  bin\n",
       "0                 KLEDLERDL   HLA-A*02:01    1\n",
       "1           IEQQADNMITEMLQK        H2-IAk    1\n",
       "2      SGEGWPYIACRTSVVGRAWE        H2-IAb    1\n",
       "3                  TRVAFAGL         H2-Kb    1\n",
       "4                 AVAKAGKPL   HLA-E*01:01    1\n",
       "5                 AMLQDIATL   HLA-E*01:01    1\n",
       "6                 KMLRGVNVL   HLA-E*01:01    1\n",
       "7                 AAVEELKAL   HLA-E*01:01    0\n",
       "8                 VEGEALATL   HLA-E*01:01    0\n",
       "9                AEWPTFNVGW   HLA-B*44:03    1\n",
       "10               APIWPYEILY   HLA-B*35:01    1\n",
       "11          VPYVNVAPSSSWTQH  H2-b class I    1\n",
       "12           YSNQYQNSIDLSAS  H2-b class I    1\n",
       "13               LLCPAGINAV        HLA-A2    0\n",
       "14              FLFDGSPTYVL   HLA-A*02:01    1\n",
       "15     LTILVALALFLLAAHASARQ  HLA-class II    0\n",
       "16                FVFLRNFSL   HLA-A*02:01    1\n",
       "17                ALENKRKQL   HLA-A*02:01    0\n",
       "18                QLAAGGKHL   HLA-A*02:01    0\n",
       "19               RTAGPSVGGV   HLA-A*02:01    0\n",
       "20               GGFVPNMLSV   HLA-A*02:01    0\n",
       "21                FLFLRNFSL   HLA-A*02:01    1\n",
       "22               FPPSPLFFFL   HLA-A*02:01    1\n",
       "23               SYVPSAEQIL         H2-Kd    1\n",
       "24                GASPAVSSL   HLA-class I    1\n",
       "25               FLPSPLFFFL   HLA-A*02:01    1\n",
       "26                CMTWNQMNL   HLA-A*24:02    1\n",
       "27                CYTWNQMNL   HLA-A*24:02    1\n",
       "28          IPGVAYTSPEVAWVG  H2-d class I    1\n",
       "29     EEASSTRGNLDVAKLNGDWF  HLA-class II    1\n",
       "...                     ...           ...  ...\n",
       "77940       PFVKIVEHHTLMTTH        H2-IEd    1\n",
       "77941             TYWCYITEL         H2-Kd    1\n",
       "77942             SYNSVKEII         H2-Kd    1\n",
       "77943             AVKNYCSKL         H2-Db    1\n",
       "77944              SNPTYSVM         H2-Kb    1\n",
       "77945             MGVANLDNL         H2-Db    1\n",
       "77946              SIINFEHL         H2-Kb    1\n",
       "77947             IVLGLIATA   HLA-A*02:01    1\n",
       "77948             KVLGLWATV   HLA-A*02:01    1\n",
       "77949             LQLCCLATA   HLA-A*02:01    1\n",
       "77950             RGTPMVITV   HLA-A*02:01    1\n",
       "77951             KLNPMLAKA   HLA-A*02:01    1\n",
       "77952             RDVPMLITT   HLA-A*02:01    1\n",
       "77953             LALPMPATA   HLA-A*02:01    1\n",
       "77954             NDFCCVATV   HLA-A*02:01    1\n",
       "77955             RINAILATA   HLA-A*02:01    1\n",
       "77956             GGNGMLATI   HLA-A*02:01    1\n",
       "77957             KDLVLLATI   HLA-A*02:01    1\n",
       "77958             RLNTVLATA   HLA-A*02:01    1\n",
       "77959             MGLPGVATV   HLA-A*02:01    1\n",
       "77960             LVLPILITI   HLA-A*02:01    1\n",
       "77961             RVNRLIIWV   HLA-A*02:01    1\n",
       "77962             SGDGLVATG   HLA-A*02:01    1\n",
       "77963             MGNGCLRIV   HLA-A*02:01    1\n",
       "77964             NGVRVLATA   HLA-A*02:01    1\n",
       "77965             MINPLVITT   HLA-A*02:01    1\n",
       "77966             NIVCPLCTL   HLA-A*02:01    1\n",
       "77967             ITNCLLSTA   HLA-A*02:01    1\n",
       "77968             KAVYNLATM         H2-Db    1\n",
       "77969             KAVCNFATM         H2-Db    1\n",
       "\n",
       "[44524 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcell_clean1=tcell_comp[tcell_comp['Allele Name'].notnull()]\n",
    "tcell_clean2=tcell_clean1[tcell_clean1['Description'].notnull()]\n",
    "tcell_clean=tcell_clean2[tcell_clean2['bin'].notnull()]\n",
    "\n",
    "print tcell_clean.shape\n",
    "tcell_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Allele Name</th>\n",
       "      <th>bin</th>\n",
       "      <th>Allel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLEDLERDL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IEQQADNMITEMLQK</td>\n",
       "      <td>H2-IAk</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGEGWPYIACRTSVVGRAWE</td>\n",
       "      <td>H2-IAb</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRVAFAGL</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVAKAGKPL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMLQDIATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMLRGVNVL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAVEELKAL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VEGEALATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEWPTFNVGW</td>\n",
       "      <td>HLA-B*44:03</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Description  Allele Name  bin  Allel\n",
       "0             KLEDLERDL  HLA-A*02:01    1     91\n",
       "1       IEQQADNMITEMLQK       H2-IAk    1     49\n",
       "2  SGEGWPYIACRTSVVGRAWE       H2-IAb    1     46\n",
       "3              TRVAFAGL        H2-Kb    1     62\n",
       "4             AVAKAGKPL  HLA-E*01:01    1    328\n",
       "5             AMLQDIATL  HLA-E*01:01    1    328\n",
       "6             KMLRGVNVL  HLA-E*01:01    1    328\n",
       "7             AAVEELKAL  HLA-E*01:01    0    328\n",
       "8             VEGEALATL  HLA-E*01:01    0    328\n",
       "9            AEWPTFNVGW  HLA-B*44:03    1    154"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.sum(tcell_clean['bin'])\n",
    "tcell_clean['Allel']=pd.Categorical.from_array(tcell_clean['Allele Name']).codes\n",
    "tcell_clean.head(10)\n",
    "#plt.hist(np.histogram(tcell_clean['Allele Name'],bins=50))\n",
    "#plt.show()\n",
    "#print np.sum(np.asarray(tcell_all['MHC Allele ID']) < 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Description', u'Allele Name', u'bin', u'Allel'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# scaling factors\n",
    "print tcell_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_ascii(letter):\n",
    "    if pd.isnull(letter):\n",
    "        return 0\n",
    "    else:\n",
    "        return ord(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44524, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
       "                9,\n",
       "            ...\n",
       "            77960, 77961, 77962, 77963, 77964, 77965, 77966, 77967, 77968,\n",
       "            77969],\n",
       "           dtype='int64', length=44524)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tcell_clean.shape\n",
    "tcell_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "1\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[73, 69, 81, 81, 65, 68, 78, 77, 73, 84, 69, 77, 76, 81, 75]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_seq=len(tcell_clean.Description.get(1))\n",
    "print tcell_clean.Allel.get(0)\n",
    "print tcell_clean.bin.get(0)\n",
    "print leng_seq\n",
    "map(to_ascii,tcell_clean.Description.get(1))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44524\n"
     ]
    }
   ],
   "source": [
    "number_data=tcell_clean.shape[0]\n",
    "number_feature=51\n",
    "tcell_data=np.zeros([number_data,number_feature+1])\n",
    "print number_data\n",
    "j=0\n",
    "for i in tcell_clean.index:\n",
    "    tcell_data[j,0]=tcell_clean.Allel.get(i)\n",
    "    tcell_data[j,number_feature]=tcell_clean.bin.get(i)\n",
    "    leng_seq=len(tcell_clean.Description.get(i))\n",
    "    if leng_seq <=number_feature-1:\n",
    "        tcell_data[j,1:leng_seq+1]=map(to_ascii,tcell_clean.Description.get(i))\n",
    "    else:\n",
    "        tcell_data[j,1:number_feature]=map(to_ascii,tcell_clean.Description.get(i))[:number_feature-1]\n",
    "    j=j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 62.  84.  82.  86.  65.  70.  65.  71.  76.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.]\n"
     ]
    }
   ],
   "source": [
    "print tcell_data[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Allele Name</th>\n",
       "      <th>bin</th>\n",
       "      <th>Allel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLEDLERDL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IEQQADNMITEMLQK</td>\n",
       "      <td>H2-IAk</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGEGWPYIACRTSVVGRAWE</td>\n",
       "      <td>H2-IAb</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRVAFAGL</td>\n",
       "      <td>H2-Kb</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVAKAGKPL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMLQDIATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMLRGVNVL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAVEELKAL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VEGEALATL</td>\n",
       "      <td>HLA-E*01:01</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEWPTFNVGW</td>\n",
       "      <td>HLA-B*44:03</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Description  Allele Name  bin  Allel\n",
       "0             KLEDLERDL  HLA-A*02:01    1     91\n",
       "1       IEQQADNMITEMLQK       H2-IAk    1     49\n",
       "2  SGEGWPYIACRTSVVGRAWE       H2-IAb    1     46\n",
       "3              TRVAFAGL        H2-Kb    1     62\n",
       "4             AVAKAGKPL  HLA-E*01:01    1    328\n",
       "5             AMLQDIATL  HLA-E*01:01    1    328\n",
       "6             KMLRGVNVL  HLA-E*01:01    1    328\n",
       "7             AAVEELKAL  HLA-E*01:01    0    328\n",
       "8             VEGEALATL  HLA-E*01:01    0    328\n",
       "9            AEWPTFNVGW  HLA-B*44:03    1    154"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcell_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 331.,   76.,   76.,   69.,   81.,   81.,   75.,   65.,   65.,\n",
       "          81.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "       [ 332.,   81.,   69.,   76.,   86.,   68.,   67.,   65.,   83.,\n",
       "          81.,   78.,   71.,   67.,   72.,   71.,   68.,   84.,   73.,\n",
       "          80.,   82.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(tcell_data)\n",
    "tcell_data[:2,:]\n",
    "#tcell_shuf.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 51) (30000, 2) (7000, 51) (7000, 2) (7524, 51) (7524, 2)\n"
     ]
    }
   ],
   "source": [
    "tcell_array=np.asarray(tcell_data)\n",
    "num_total=tcell_array.shape[0]\n",
    "train_num=30000\n",
    "valid_num=7000\n",
    "test_num=num_total-train_num-valid_num\n",
    "train_set=tcell_array[:train_num,:number_feature]\n",
    "#train_lable=tcell_array[:train_num,number_feature]\n",
    "train_lable=(np.arange(2)==tcell_array[:train_num,number_feature][:,None]).astype(np.float32)\n",
    "\n",
    "valid_set=tcell_array[train_num:train_num+valid_num,:number_feature]\n",
    "#valid_lable=tcell_array[]\n",
    "valid_lable=(np.arange(2)==tcell_array[train_num:train_num+valid_num,number_feature][:,None]).astype(np.float32)\n",
    "\n",
    "test_set=tcell_array[train_num+valid_num:,:number_feature]\n",
    "#test_lable=tcell_array[train_num+valid_num:,number_feature]\n",
    "test_lable=(np.arange(2)==tcell_array[train_num+valid_num:,number_feature][:,None]).astype(np.float32)\n",
    "\n",
    "print train_set.shape, train_lable.shape, valid_set.shape, valid_lable.shape, test_set.shape, test_lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "hidden_size=100\n",
    "num_lable=2\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_set_batch=tf.placeholder(tf.float32,shape=(batch_size,number_feature))\n",
    "    train_lable_batch=tf.placeholder(tf.float32,shape=(batch_size,num_lable))\n",
    "    \n",
    "    valid_set_tf=tf.constant(valid_set.astype(np.float32))\n",
    "    test_set_tf=tf.constant(test_set.astype(np.float32))\n",
    "    \n",
    "    weights1=tf.Variable(tf.truncated_normal([number_feature,hidden_size]))\n",
    "    bias1=tf.Variable(tf.zeros([hidden_size]))\n",
    "    \n",
    "    weights2=tf.Variable(tf.truncated_normal([hidden_size,num_lable]))\n",
    "    bias2=tf.Variable(tf.zeros([num_lable]))\n",
    "    \n",
    "    logits1=tf.matmul(train_set_batch,weights1)+bias1\n",
    "    act1=tf.nn.relu(logits1)\n",
    "    logits=tf.matmul(act1,weights2)+bias2\n",
    "\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits,train_lable_batch))\n",
    "    \n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.00005).minimize(loss)\n",
    "    \n",
    "    train_pred=tf.nn.softmax(logits)\n",
    "    valid_pred=tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(valid_set_tf,weights1)+bias1),weights2)+bias2)\n",
    "    test_pred=tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(test_set_tf,weights1)+bias1),weights2)+bias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([1,2,3])*np.array([1,2,3]))\n",
    "np.sum(train_lable[:,1])\n",
    "1-np.argmax(np.array([[0.1,0.6],[0.,0.9],[0.8,0.1]]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 248.767426\n",
      "Minibatch accuracy: 16.6%\n",
      "Validation accuracy: 36.0%\n",
      "Minibatch loss at step 20: 151.582779\n",
      "Minibatch accuracy: 45.8%\n",
      "Validation accuracy: 46.1%\n",
      "Minibatch loss at step 40: 166.709595\n",
      "Minibatch accuracy: 41.0%\n",
      "Validation accuracy: 47.3%\n",
      "Minibatch loss at step 60: 149.081772\n",
      "Minibatch accuracy: 46.5%\n",
      "Validation accuracy: 47.3%\n",
      "Minibatch loss at step 80: 131.703171\n",
      "Minibatch accuracy: 48.6%\n",
      "Validation accuracy: 47.3%\n",
      "Minibatch loss at step 100: 147.153473\n",
      "Minibatch accuracy: 43.3%\n",
      "Validation accuracy: 48.9%\n",
      "Minibatch loss at step 120: 130.955261\n",
      "Minibatch accuracy: 45.8%\n",
      "Validation accuracy: 48.1%\n",
      "Minibatch loss at step 140: 115.966362\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 48.1%\n",
      "Minibatch loss at step 160: 130.486893\n",
      "Minibatch accuracy: 44.5%\n",
      "Validation accuracy: 49.8%\n",
      "Minibatch loss at step 180: 115.293640\n",
      "Minibatch accuracy: 46.4%\n",
      "Validation accuracy: 49.5%\n",
      "Minibatch loss at step 200: 102.301773\n",
      "Minibatch accuracy: 49.7%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 220: 115.877037\n",
      "Minibatch accuracy: 44.7%\n",
      "Validation accuracy: 50.5%\n",
      "Minibatch loss at step 240: 103.152824\n",
      "Minibatch accuracy: 47.1%\n",
      "Validation accuracy: 50.3%\n",
      "Minibatch loss at step 260: 91.612999\n",
      "Minibatch accuracy: 51.2%\n",
      "Validation accuracy: 49.1%\n",
      "Minibatch loss at step 280: 104.234352\n",
      "Minibatch accuracy: 45.9%\n",
      "Validation accuracy: 50.9%\n",
      "Minibatch loss at step 300: 94.553963\n",
      "Minibatch accuracy: 47.6%\n",
      "Validation accuracy: 51.8%\n",
      "Minibatch loss at step 320: 83.599762\n",
      "Minibatch accuracy: 50.6%\n",
      "Validation accuracy: 50.1%\n",
      "Minibatch loss at step 340: 95.192955\n",
      "Minibatch accuracy: 46.5%\n",
      "Validation accuracy: 51.2%\n",
      "Minibatch loss at step 360: 87.935440\n",
      "Minibatch accuracy: 47.5%\n",
      "Validation accuracy: 52.5%\n",
      "Minibatch loss at step 380: 77.045662\n",
      "Minibatch accuracy: 50.2%\n",
      "Validation accuracy: 51.3%\n",
      "Minibatch loss at step 400: 87.623581\n",
      "Minibatch accuracy: 44.3%\n",
      "Validation accuracy: 52.9%\n",
      "Minibatch loss at step 420: 82.387680\n",
      "Minibatch accuracy: 46.8%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 440: 71.172791\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 52.2%\n",
      "Minibatch loss at step 460: 80.621315\n",
      "Minibatch accuracy: 46.4%\n",
      "Validation accuracy: 53.0%\n",
      "Minibatch loss at step 480: 77.140472\n",
      "Minibatch accuracy: 47.4%\n",
      "Validation accuracy: 53.4%\n",
      "Minibatch loss at step 500: 65.329964\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 520: 74.031532\n",
      "Minibatch accuracy: 46.3%\n",
      "Validation accuracy: 53.4%\n",
      "Minibatch loss at step 540: 71.701424\n",
      "Minibatch accuracy: 49.4%\n",
      "Validation accuracy: 53.7%\n",
      "Minibatch loss at step 560: 60.018631\n",
      "Minibatch accuracy: 46.7%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 580: 68.011795\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 600: 66.457405\n",
      "Minibatch accuracy: 51.2%\n",
      "Validation accuracy: 53.7%\n",
      "Minibatch loss at step 620: 55.430836\n",
      "Minibatch accuracy: 47.2%\n",
      "Validation accuracy: 54.3%\n",
      "Minibatch loss at step 640: 62.951908\n",
      "Minibatch accuracy: 48.1%\n",
      "Validation accuracy: 53.4%\n",
      "Minibatch loss at step 660: 62.322411\n",
      "Minibatch accuracy: 50.8%\n",
      "Validation accuracy: 54.6%\n",
      "Minibatch loss at step 680: 53.372837\n",
      "Minibatch accuracy: 44.4%\n",
      "Validation accuracy: 56.0%\n",
      "Minibatch loss at step 700: 59.016064\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 54.9%\n",
      "Minibatch loss at step 720: 59.627552\n",
      "Minibatch accuracy: 48.5%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 740: 51.344757\n",
      "Minibatch accuracy: 42.1%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 760: 57.142780\n",
      "Minibatch accuracy: 43.0%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 780: 60.272911\n",
      "Minibatch accuracy: 41.0%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 800: 51.717224\n",
      "Minibatch accuracy: 36.8%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 820: 55.098473\n",
      "Minibatch accuracy: 41.6%\n",
      "Validation accuracy: 57.3%\n",
      "Minibatch loss at step 840: 62.390762\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 56.2%\n",
      "Minibatch loss at step 860: 53.737236\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 880: 54.735771\n",
      "Minibatch accuracy: 40.4%\n",
      "Validation accuracy: 57.1%\n",
      "Minibatch loss at step 900: 62.187355\n",
      "Minibatch accuracy: 33.5%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 920: 52.904037\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 940: 51.872665\n",
      "Minibatch accuracy: 40.7%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 960: 63.788891\n",
      "Minibatch accuracy: 32.2%\n",
      "Validation accuracy: 55.9%\n",
      "Minibatch loss at step 980: 51.787704\n",
      "Minibatch accuracy: 30.1%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 1000: 50.013515\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 1020: 64.646225\n",
      "Minibatch accuracy: 29.9%\n",
      "Validation accuracy: 56.1%\n",
      "Minibatch loss at step 1040: 51.725967\n",
      "Minibatch accuracy: 30.2%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 1060: 48.322422\n",
      "Minibatch accuracy: 39.3%\n",
      "Validation accuracy: 57.2%\n",
      "Minibatch loss at step 1080: 66.368034\n",
      "Minibatch accuracy: 27.6%\n",
      "Validation accuracy: 56.1%\n",
      "Minibatch loss at step 1100: 52.568428\n",
      "Minibatch accuracy: 29.4%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 1120: 47.330482\n",
      "Minibatch accuracy: 38.7%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 1140: 66.573639\n",
      "Minibatch accuracy: 26.3%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 1160: 52.076706\n",
      "Minibatch accuracy: 28.2%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 1180: 47.156803\n",
      "Minibatch accuracy: 37.0%\n",
      "Validation accuracy: 56.0%\n",
      "Minibatch loss at step 1200: 67.933769\n",
      "Minibatch accuracy: 23.8%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 1220: 51.336025\n",
      "Minibatch accuracy: 27.7%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 1240: 45.985954\n",
      "Minibatch accuracy: 36.3%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 1260: 69.189072\n",
      "Minibatch accuracy: 22.1%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 1280: 52.913681\n",
      "Minibatch accuracy: 27.3%\n",
      "Validation accuracy: 57.0%\n",
      "Minibatch loss at step 1300: 43.846561\n",
      "Minibatch accuracy: 36.6%\n",
      "Validation accuracy: 56.0%\n",
      "Minibatch loss at step 1320: 69.809746\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 1340: 53.255032\n",
      "Minibatch accuracy: 26.5%\n",
      "Validation accuracy: 57.1%\n",
      "Minibatch loss at step 1360: 42.468777\n",
      "Minibatch accuracy: 37.0%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 1380: 70.006706\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 1400: 52.435650\n",
      "Minibatch accuracy: 26.1%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 1420: 40.937553\n",
      "Minibatch accuracy: 38.8%\n",
      "Validation accuracy: 55.9%\n",
      "Minibatch loss at step 1440: 70.673721\n",
      "Minibatch accuracy: 18.9%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 1460: 52.120434\n",
      "Minibatch accuracy: 23.8%\n",
      "Validation accuracy: 56.1%\n",
      "Minibatch loss at step 1480: 39.873856\n",
      "Minibatch accuracy: 39.2%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 1500: 70.531578\n",
      "Minibatch accuracy: 18.5%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 1520: 53.403835\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 1540: 39.199051\n",
      "Minibatch accuracy: 39.2%\n",
      "Validation accuracy: 55.6%\n",
      "Minibatch loss at step 1560: 71.933113\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 57.0%\n",
      "Minibatch loss at step 1580: 52.262203\n",
      "Minibatch accuracy: 22.9%\n",
      "Validation accuracy: 56.2%\n",
      "Minibatch loss at step 1600: 42.928814\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 1620: 72.715858\n",
      "Minibatch accuracy: 15.7%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 1640: 51.645145\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 56.1%\n",
      "Minibatch loss at step 1660: 42.894032\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 1680: 72.734947\n",
      "Minibatch accuracy: 15.2%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 1700: 51.656887\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 1720: 41.572678\n",
      "Minibatch accuracy: 32.4%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 1740: 73.478752\n",
      "Minibatch accuracy: 14.2%\n",
      "Validation accuracy: 57.7%\n",
      "Minibatch loss at step 1760: 52.092960\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 1780: 41.680576\n",
      "Minibatch accuracy: 32.4%\n",
      "Validation accuracy: 53.7%\n",
      "Minibatch loss at step 1800: 73.627617\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 57.8%\n",
      "Minibatch loss at step 1820: 52.416298\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 56.9%\n",
      "Minibatch loss at step 1840: 41.059101\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 53.0%\n",
      "Minibatch loss at step 1860: 74.771896\n",
      "Minibatch accuracy: 12.7%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 1880: 52.111187\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 56.9%\n",
      "Minibatch loss at step 1900: 40.487213\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 52.7%\n",
      "Minibatch loss at step 1920: 74.456657\n",
      "Minibatch accuracy: 12.7%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 1940: 52.440933\n",
      "Minibatch accuracy: 22.0%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 1960: 38.886780\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 52.4%\n",
      "Minibatch loss at step 1980: 73.585297\n",
      "Minibatch accuracy: 13.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 2000: 51.785397\n",
      "Minibatch accuracy: 22.0%\n",
      "Validation accuracy: 57.2%\n",
      "Minibatch loss at step 2020: 38.042664\n",
      "Minibatch accuracy: 32.4%\n",
      "Validation accuracy: 51.8%\n",
      "Minibatch loss at step 2040: 73.008957\n",
      "Minibatch accuracy: 13.2%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 2060: 50.778610\n",
      "Minibatch accuracy: 23.0%\n",
      "Validation accuracy: 57.2%\n",
      "Minibatch loss at step 2080: 38.016991\n",
      "Minibatch accuracy: 32.4%\n",
      "Validation accuracy: 52.1%\n",
      "Minibatch loss at step 2100: 71.740891\n",
      "Minibatch accuracy: 13.2%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 2120: 50.529522\n",
      "Minibatch accuracy: 22.0%\n",
      "Validation accuracy: 57.1%\n",
      "Minibatch loss at step 2140: 35.892227\n",
      "Minibatch accuracy: 33.1%\n",
      "Validation accuracy: 52.3%\n",
      "Minibatch loss at step 2160: 72.431267\n",
      "Minibatch accuracy: 12.7%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 2180: 46.759979\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 55.9%\n",
      "Minibatch loss at step 2200: 35.860119\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 52.2%\n",
      "Minibatch loss at step 2220: 71.416519\n",
      "Minibatch accuracy: 12.7%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 2240: 46.924423\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 2260: 35.818943\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 2280: 71.857765\n",
      "Minibatch accuracy: 12.7%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 2300: 48.374001\n",
      "Minibatch accuracy: 23.0%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 2320: 35.071861\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 2340: 71.024055\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 2360: 49.287685\n",
      "Minibatch accuracy: 22.0%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 2380: 34.447556\n",
      "Minibatch accuracy: 34.7%\n",
      "Validation accuracy: 51.8%\n",
      "Minibatch loss at step 2400: 70.649055\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 2420: 53.101284\n",
      "Minibatch accuracy: 19.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 2440: 36.216011\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 2460: 66.784218\n",
      "Minibatch accuracy: 16.6%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 2480: 49.794090\n",
      "Minibatch accuracy: 22.0%\n",
      "Validation accuracy: 57.5%\n",
      "Minibatch loss at step 2500: 36.838249\n",
      "Minibatch accuracy: 30.0%\n",
      "Validation accuracy: 51.3%\n",
      "Minibatch loss at step 2520: 68.565979\n",
      "Minibatch accuracy: 15.7%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 2540: 50.670082\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 2560: 36.640045\n",
      "Minibatch accuracy: 30.4%\n",
      "Validation accuracy: 51.0%\n",
      "Minibatch loss at step 2580: 64.744217\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 2600: 51.582882\n",
      "Minibatch accuracy: 20.6%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 2620: 41.062130\n",
      "Minibatch accuracy: 24.5%\n",
      "Validation accuracy: 51.2%\n",
      "Minibatch loss at step 2640: 67.796921\n",
      "Minibatch accuracy: 16.2%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 2660: 46.653851\n",
      "Minibatch accuracy: 24.3%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 2680: 37.265770\n",
      "Minibatch accuracy: 28.4%\n",
      "Validation accuracy: 50.4%\n",
      "Minibatch loss at step 2700: 67.377144\n",
      "Minibatch accuracy: 16.2%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 2720: 44.156357\n",
      "Minibatch accuracy: 26.1%\n",
      "Validation accuracy: 56.0%\n",
      "Minibatch loss at step 2740: 38.171032\n",
      "Minibatch accuracy: 26.7%\n",
      "Validation accuracy: 50.5%\n",
      "Minibatch loss at step 2760: 66.123222\n",
      "Minibatch accuracy: 16.6%\n",
      "Validation accuracy: 59.3%\n",
      "Minibatch loss at step 2780: 45.119915\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 2800: 37.520679\n",
      "Minibatch accuracy: 28.4%\n",
      "Validation accuracy: 50.9%\n",
      "Minibatch loss at step 2820: 64.553947\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 2840: 43.123768\n",
      "Minibatch accuracy: 26.5%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 2860: 37.025196\n",
      "Minibatch accuracy: 28.4%\n",
      "Validation accuracy: 50.9%\n",
      "Minibatch loss at step 2880: 64.365303\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 2900: 41.384335\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 55.5%\n",
      "Minibatch loss at step 2920: 36.644829\n",
      "Minibatch accuracy: 29.6%\n",
      "Validation accuracy: 51.5%\n",
      "Minibatch loss at step 2940: 64.267822\n",
      "Minibatch accuracy: 16.6%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 2960: 39.800915\n",
      "Minibatch accuracy: 27.8%\n",
      "Validation accuracy: 54.6%\n",
      "Minibatch loss at step 2980: 36.059082\n",
      "Minibatch accuracy: 30.9%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 3000: 62.708027\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 3020: 44.227074\n",
      "Minibatch accuracy: 26.1%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 3040: 36.020710\n",
      "Minibatch accuracy: 30.0%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 3060: 62.019119\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 3080: 46.450855\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 3100: 35.997780\n",
      "Minibatch accuracy: 29.6%\n",
      "Validation accuracy: 51.2%\n",
      "Minibatch loss at step 3120: 61.978992\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 3140: 45.394695\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 3160: 34.781437\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 3180: 62.092682\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 3200: 44.629955\n",
      "Minibatch accuracy: 25.7%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 3220: 34.035671\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 3240: 61.743088\n",
      "Minibatch accuracy: 18.1%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 3260: 45.000469\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 3280: 32.776821\n",
      "Minibatch accuracy: 33.2%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 3300: 61.774860\n",
      "Minibatch accuracy: 18.1%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 3320: 46.207664\n",
      "Minibatch accuracy: 23.9%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 3340: 32.011292\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 51.8%\n",
      "Minibatch loss at step 3360: 62.362461\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 59.0%\n",
      "Minibatch loss at step 3380: 44.985252\n",
      "Minibatch accuracy: 24.3%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 3400: 31.364172\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 3420: 63.166962\n",
      "Minibatch accuracy: 15.7%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 3440: 43.390648\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 3460: 31.023661\n",
      "Minibatch accuracy: 35.1%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 3480: 62.495853\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 3500: 43.790375\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 3520: 30.652493\n",
      "Minibatch accuracy: 35.5%\n",
      "Validation accuracy: 52.1%\n",
      "Minibatch loss at step 3540: 62.132957\n",
      "Minibatch accuracy: 16.6%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 3560: 43.161793\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 3580: 30.745108\n",
      "Minibatch accuracy: 35.9%\n",
      "Validation accuracy: 52.1%\n",
      "Minibatch loss at step 3600: 61.461758\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 3620: 43.387821\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 3640: 30.966499\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 3660: 60.526867\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 3680: 43.535908\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 3700: 31.123747\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 51.3%\n",
      "Minibatch loss at step 3720: 59.647556\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 3740: 43.689346\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 3760: 31.154858\n",
      "Minibatch accuracy: 32.9%\n",
      "Validation accuracy: 51.0%\n",
      "Minibatch loss at step 3780: 59.481754\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 3800: 46.184444\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 3820: 31.263470\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 3840: 61.058155\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 3860: 46.074898\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 3880: 31.321365\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 3900: 63.013000\n",
      "Minibatch accuracy: 15.2%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 3920: 46.924389\n",
      "Minibatch accuracy: 18.3%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 3940: 31.367292\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 3960: 61.680050\n",
      "Minibatch accuracy: 16.2%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 3980: 46.358391\n",
      "Minibatch accuracy: 19.2%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 4000: 31.612129\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 4020: 60.210892\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 4040: 46.256721\n",
      "Minibatch accuracy: 18.7%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 4060: 31.285583\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.2%\n",
      "Minibatch loss at step 4080: 61.446438\n",
      "Minibatch accuracy: 15.7%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 4100: 46.166649\n",
      "Minibatch accuracy: 18.3%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 4120: 31.678288\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.5%\n",
      "Minibatch loss at step 4140: 61.106548\n",
      "Minibatch accuracy: 16.2%\n",
      "Validation accuracy: 59.5%\n",
      "Minibatch loss at step 4160: 45.981167\n",
      "Minibatch accuracy: 18.3%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 4180: 31.171438\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 4200: 63.027023\n",
      "Minibatch accuracy: 14.7%\n",
      "Validation accuracy: 60.4%\n",
      "Minibatch loss at step 4220: 45.960663\n",
      "Minibatch accuracy: 18.3%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 4240: 31.206898\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.5%\n",
      "Minibatch loss at step 4260: 63.303337\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 4280: 45.912476\n",
      "Minibatch accuracy: 17.8%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 4300: 31.169886\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.5%\n",
      "Minibatch loss at step 4320: 62.897701\n",
      "Minibatch accuracy: 14.2%\n",
      "Validation accuracy: 60.5%\n",
      "Minibatch loss at step 4340: 45.719189\n",
      "Minibatch accuracy: 17.8%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 4360: 30.863098\n",
      "Minibatch accuracy: 31.6%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 4380: 63.837173\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 4400: 45.916382\n",
      "Minibatch accuracy: 17.3%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 4420: 30.955610\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 4440: 63.537239\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 4460: 45.855160\n",
      "Minibatch accuracy: 17.3%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 4480: 30.908825\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 4500: 62.119274\n",
      "Minibatch accuracy: 14.7%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 4520: 45.072624\n",
      "Minibatch accuracy: 18.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 4540: 30.781073\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 4560: 62.066772\n",
      "Minibatch accuracy: 14.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 4580: 45.023300\n",
      "Minibatch accuracy: 18.2%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 4600: 30.391315\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 4620: 57.632919\n",
      "Minibatch accuracy: 18.5%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 4640: 41.511189\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 4660: 30.157894\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 51.8%\n",
      "Minibatch loss at step 4680: 57.329937\n",
      "Minibatch accuracy: 18.5%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 4700: 40.787060\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 4720: 30.127056\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 51.4%\n",
      "Minibatch loss at step 4740: 57.835339\n",
      "Minibatch accuracy: 17.1%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 4760: 42.516670\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 4780: 30.046259\n",
      "Minibatch accuracy: 31.7%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 4800: 57.972672\n",
      "Minibatch accuracy: 16.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 4820: 44.474731\n",
      "Minibatch accuracy: 17.8%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 4840: 29.977365\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 51.0%\n",
      "Minibatch loss at step 4860: 58.376030\n",
      "Minibatch accuracy: 15.7%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 4880: 45.815765\n",
      "Minibatch accuracy: 15.3%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 4900: 30.101137\n",
      "Minibatch accuracy: 30.9%\n",
      "Validation accuracy: 50.6%\n",
      "Minibatch loss at step 4920: 56.095970\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 57.8%\n",
      "Minibatch loss at step 4940: 45.600040\n",
      "Minibatch accuracy: 15.8%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 4960: 30.210844\n",
      "Minibatch accuracy: 30.5%\n",
      "Validation accuracy: 50.6%\n",
      "Minibatch loss at step 4980: 56.272640\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 5000: 40.712063\n",
      "Minibatch accuracy: 23.9%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 5020: 30.936241\n",
      "Minibatch accuracy: 30.1%\n",
      "Validation accuracy: 50.3%\n",
      "Minibatch loss at step 5040: 55.658730\n",
      "Minibatch accuracy: 18.1%\n",
      "Validation accuracy: 57.5%\n",
      "Minibatch loss at step 5060: 40.966835\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 5080: 31.213644\n",
      "Minibatch accuracy: 30.1%\n",
      "Validation accuracy: 49.5%\n",
      "Minibatch loss at step 5100: 55.272060\n",
      "Minibatch accuracy: 18.5%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 5120: 41.711823\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 5140: 30.753151\n",
      "Minibatch accuracy: 30.1%\n",
      "Validation accuracy: 50.1%\n",
      "Minibatch loss at step 5160: 55.508392\n",
      "Minibatch accuracy: 18.1%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 5180: 41.117329\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 5200: 30.302706\n",
      "Minibatch accuracy: 30.5%\n",
      "Validation accuracy: 50.3%\n",
      "Minibatch loss at step 5220: 56.128502\n",
      "Minibatch accuracy: 17.6%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 5240: 37.912514\n",
      "Minibatch accuracy: 24.8%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 5260: 29.164448\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 50.7%\n",
      "Minibatch loss at step 5280: 62.343922\n",
      "Minibatch accuracy: 11.8%\n",
      "Validation accuracy: 61.2%\n",
      "Minibatch loss at step 5300: 34.506462\n",
      "Minibatch accuracy: 28.7%\n",
      "Validation accuracy: 55.4%\n",
      "Minibatch loss at step 5320: 28.002241\n",
      "Minibatch accuracy: 33.2%\n",
      "Validation accuracy: 51.0%\n",
      "Minibatch loss at step 5340: 59.231186\n",
      "Minibatch accuracy: 14.2%\n",
      "Validation accuracy: 59.8%\n",
      "Minibatch loss at step 5360: 33.925865\n",
      "Minibatch accuracy: 29.1%\n",
      "Validation accuracy: 55.0%\n",
      "Minibatch loss at step 5380: 27.625391\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 51.4%\n",
      "Minibatch loss at step 5400: 61.503048\n",
      "Minibatch accuracy: 12.8%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 5420: 33.057785\n",
      "Minibatch accuracy: 30.4%\n",
      "Validation accuracy: 54.8%\n",
      "Minibatch loss at step 5440: 27.415152\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 50.9%\n",
      "Minibatch loss at step 5460: 65.153259\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 62.9%\n",
      "Minibatch loss at step 5480: 33.083164\n",
      "Minibatch accuracy: 30.8%\n",
      "Validation accuracy: 54.7%\n",
      "Minibatch loss at step 5500: 27.892883\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 49.7%\n",
      "Minibatch loss at step 5520: 65.971596\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.4%\n",
      "Minibatch loss at step 5540: 35.320572\n",
      "Minibatch accuracy: 27.0%\n",
      "Validation accuracy: 55.6%\n",
      "Minibatch loss at step 5560: 27.768499\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 5580: 65.872276\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.5%\n",
      "Minibatch loss at step 5600: 23.492271\n",
      "Minibatch accuracy: 45.1%\n",
      "Validation accuracy: 56.3%\n",
      "Minibatch loss at step 5620: 26.262789\n",
      "Minibatch accuracy: 36.3%\n",
      "Validation accuracy: 52.8%\n",
      "Minibatch loss at step 5640: 66.880074\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 64.0%\n",
      "Minibatch loss at step 5660: 36.030266\n",
      "Minibatch accuracy: 25.2%\n",
      "Validation accuracy: 55.0%\n",
      "Minibatch loss at step 5680: 25.069637\n",
      "Minibatch accuracy: 41.7%\n",
      "Validation accuracy: 55.9%\n",
      "Minibatch loss at step 5700: 66.084747\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.7%\n",
      "Minibatch loss at step 5720: 42.339165\n",
      "Minibatch accuracy: 17.8%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 5740: 27.021875\n",
      "Minibatch accuracy: 33.3%\n",
      "Validation accuracy: 49.9%\n",
      "Minibatch loss at step 5760: 64.747986\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.2%\n",
      "Minibatch loss at step 5780: 24.857840\n",
      "Minibatch accuracy: 42.1%\n",
      "Validation accuracy: 54.1%\n",
      "Minibatch loss at step 5800: 26.477901\n",
      "Minibatch accuracy: 34.8%\n",
      "Validation accuracy: 49.3%\n",
      "Minibatch loss at step 5820: 64.207787\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 62.5%\n",
      "Minibatch loss at step 5840: 25.867931\n",
      "Minibatch accuracy: 39.3%\n",
      "Validation accuracy: 53.1%\n",
      "Minibatch loss at step 5860: 27.222700\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 48.7%\n",
      "Minibatch loss at step 5880: 64.807785\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.4%\n",
      "Minibatch loss at step 5900: 25.004564\n",
      "Minibatch accuracy: 41.8%\n",
      "Validation accuracy: 53.8%\n",
      "Minibatch loss at step 5920: 24.004534\n",
      "Minibatch accuracy: 43.4%\n",
      "Validation accuracy: 55.8%\n",
      "Minibatch loss at step 5940: 65.225563\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.7%\n",
      "Minibatch loss at step 5960: 21.890684\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 5980: 24.383577\n",
      "Minibatch accuracy: 41.7%\n",
      "Validation accuracy: 54.4%\n",
      "Minibatch loss at step 6000: 46.819798\n",
      "Minibatch accuracy: 21.7%\n",
      "Validation accuracy: 52.2%\n",
      "Minibatch loss at step 6020: 30.563271\n",
      "Minibatch accuracy: 32.5%\n",
      "Validation accuracy: 52.5%\n",
      "Minibatch loss at step 6040: 24.165329\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 54.7%\n",
      "Minibatch loss at step 6060: 64.561401\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.5%\n",
      "Minibatch loss at step 6080: 21.220081\n",
      "Minibatch accuracy: 48.6%\n",
      "Validation accuracy: 56.9%\n",
      "Minibatch loss at step 6100: 23.848192\n",
      "Minibatch accuracy: 42.4%\n",
      "Validation accuracy: 54.9%\n",
      "Minibatch loss at step 6120: 60.378719\n",
      "Minibatch accuracy: 11.3%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 6140: 22.156012\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 55.7%\n",
      "Minibatch loss at step 6160: 24.507511\n",
      "Minibatch accuracy: 39.6%\n",
      "Validation accuracy: 52.1%\n",
      "Minibatch loss at step 6180: 66.284058\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 64.4%\n",
      "Minibatch loss at step 6200: 20.972195\n",
      "Minibatch accuracy: 48.3%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 6220: 24.181417\n",
      "Minibatch accuracy: 39.6%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 6240: 66.313423\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 64.4%\n",
      "Minibatch loss at step 6260: 20.351337\n",
      "Minibatch accuracy: 49.4%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 6280: 23.922668\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 52.5%\n",
      "Minibatch loss at step 6300: 66.355026\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 64.6%\n",
      "Minibatch loss at step 6320: 20.574524\n",
      "Minibatch accuracy: 49.1%\n",
      "Validation accuracy: 57.0%\n",
      "Minibatch loss at step 6340: 23.716520\n",
      "Minibatch accuracy: 39.6%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 6360: 65.869980\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 64.3%\n",
      "Minibatch loss at step 6380: 20.307207\n",
      "Minibatch accuracy: 49.1%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 6400: 23.764727\n",
      "Minibatch accuracy: 39.2%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 6420: 66.969986\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 65.0%\n",
      "Minibatch loss at step 6440: 29.598375\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 6460: 23.557457\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 52.3%\n",
      "Minibatch loss at step 6480: 63.255257\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.5%\n",
      "Minibatch loss at step 6500: 18.140438\n",
      "Minibatch accuracy: 57.3%\n",
      "Validation accuracy: 63.1%\n",
      "Minibatch loss at step 6520: 28.685331\n",
      "Minibatch accuracy: 28.8%\n",
      "Validation accuracy: 46.9%\n",
      "Minibatch loss at step 6540: 62.574657\n",
      "Minibatch accuracy: 9.2%\n",
      "Validation accuracy: 63.2%\n",
      "Minibatch loss at step 6560: 19.510605\n",
      "Minibatch accuracy: 50.8%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 6580: 23.717970\n",
      "Minibatch accuracy: 39.2%\n",
      "Validation accuracy: 51.7%\n",
      "Minibatch loss at step 6600: 59.509495\n",
      "Minibatch accuracy: 11.3%\n",
      "Validation accuracy: 60.9%\n",
      "Minibatch loss at step 6620: 19.426588\n",
      "Minibatch accuracy: 51.1%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 6640: 23.536137\n",
      "Minibatch accuracy: 39.2%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 6660: 65.234718\n",
      "Minibatch accuracy: 8.2%\n",
      "Validation accuracy: 64.5%\n",
      "Minibatch loss at step 6680: 18.685163\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 60.5%\n",
      "Minibatch loss at step 6700: 27.433855\n",
      "Minibatch accuracy: 29.7%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 6720: 59.111446\n",
      "Minibatch accuracy: 11.3%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 6740: 20.006239\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 6760: 22.824646\n",
      "Minibatch accuracy: 40.7%\n",
      "Validation accuracy: 51.2%\n",
      "Minibatch loss at step 6780: 49.031227\n",
      "Minibatch accuracy: 18.5%\n",
      "Validation accuracy: 52.7%\n",
      "Minibatch loss at step 6800: 31.406164\n",
      "Minibatch accuracy: 29.6%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 6820: 22.506273\n",
      "Minibatch accuracy: 42.7%\n",
      "Validation accuracy: 53.9%\n",
      "Minibatch loss at step 6840: 47.872112\n",
      "Minibatch accuracy: 19.5%\n",
      "Validation accuracy: 52.4%\n",
      "Minibatch loss at step 6860: 28.117109\n",
      "Minibatch accuracy: 33.3%\n",
      "Validation accuracy: 51.1%\n",
      "Minibatch loss at step 6880: 21.464937\n",
      "Minibatch accuracy: 45.0%\n",
      "Validation accuracy: 56.2%\n",
      "Minibatch loss at step 6900: 58.522041\n",
      "Minibatch accuracy: 11.8%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 6920: 41.215385\n",
      "Minibatch accuracy: 16.3%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 6940: 21.293062\n",
      "Minibatch accuracy: 45.6%\n",
      "Validation accuracy: 57.1%\n",
      "Minibatch loss at step 6960: 57.151329\n",
      "Minibatch accuracy: 11.8%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 6980: 43.278149\n",
      "Minibatch accuracy: 14.3%\n",
      "Validation accuracy: 60.8%\n",
      "Minibatch loss at step 7000: 20.850103\n",
      "Minibatch accuracy: 48.1%\n",
      "Validation accuracy: 58.9%\n",
      "Minibatch loss at step 7020: 56.133842\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 7040: 43.048183\n",
      "Minibatch accuracy: 14.3%\n",
      "Validation accuracy: 61.2%\n",
      "Minibatch loss at step 7060: 20.476839\n",
      "Minibatch accuracy: 48.9%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7080: 57.547749\n",
      "Minibatch accuracy: 11.8%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 7100: 40.564060\n",
      "Minibatch accuracy: 15.8%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 7120: 20.359241\n",
      "Minibatch accuracy: 49.8%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 7140: 55.740246\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 7160: 38.030231\n",
      "Minibatch accuracy: 21.1%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 7180: 20.377457\n",
      "Minibatch accuracy: 49.5%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 7200: 57.257259\n",
      "Minibatch accuracy: 11.8%\n",
      "Validation accuracy: 62.0%\n",
      "Minibatch loss at step 7220: 37.347958\n",
      "Minibatch accuracy: 21.6%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 7240: 20.628521\n",
      "Minibatch accuracy: 48.7%\n",
      "Validation accuracy: 60.3%\n",
      "Minibatch loss at step 7260: 55.652866\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 7280: 38.886063\n",
      "Minibatch accuracy: 20.6%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 7300: 20.676989\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 60.2%\n",
      "Minibatch loss at step 7320: 54.676342\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 7340: 37.704308\n",
      "Minibatch accuracy: 21.1%\n",
      "Validation accuracy: 59.7%\n",
      "Minibatch loss at step 7360: 20.745031\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 59.9%\n",
      "Minibatch loss at step 7380: 54.469219\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7400: 36.480255\n",
      "Minibatch accuracy: 22.1%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 7420: 20.742786\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 60.0%\n",
      "Minibatch loss at step 7440: 54.102039\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.4%\n",
      "Minibatch loss at step 7460: 35.888256\n",
      "Minibatch accuracy: 22.5%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 7480: 20.594265\n",
      "Minibatch accuracy: 49.1%\n",
      "Validation accuracy: 60.2%\n",
      "Minibatch loss at step 7500: 54.223152\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7520: 35.559402\n",
      "Minibatch accuracy: 23.0%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 7540: 20.423342\n",
      "Minibatch accuracy: 49.1%\n",
      "Validation accuracy: 60.5%\n",
      "Minibatch loss at step 7560: 54.043808\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7580: 35.078075\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 57.8%\n",
      "Minibatch loss at step 7600: 20.306433\n",
      "Minibatch accuracy: 49.4%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7620: 53.761288\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 7640: 34.878242\n",
      "Minibatch accuracy: 23.9%\n",
      "Validation accuracy: 57.8%\n",
      "Minibatch loss at step 7660: 20.228914\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7680: 53.686516\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 7700: 34.873428\n",
      "Minibatch accuracy: 23.9%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 7720: 20.152388\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 60.8%\n",
      "Minibatch loss at step 7740: 53.704117\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 60.8%\n",
      "Minibatch loss at step 7760: 34.579563\n",
      "Minibatch accuracy: 23.9%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 7780: 20.015606\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 7800: 53.690788\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 60.9%\n",
      "Minibatch loss at step 7820: 33.485867\n",
      "Minibatch accuracy: 25.7%\n",
      "Validation accuracy: 57.9%\n",
      "Minibatch loss at step 7840: 19.810528\n",
      "Minibatch accuracy: 49.9%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 7860: 53.659801\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 7880: 33.296085\n",
      "Minibatch accuracy: 26.1%\n",
      "Validation accuracy: 57.8%\n",
      "Minibatch loss at step 7900: 19.708900\n",
      "Minibatch accuracy: 49.9%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 7920: 53.521873\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 7940: 32.654774\n",
      "Minibatch accuracy: 27.0%\n",
      "Validation accuracy: 57.7%\n",
      "Minibatch loss at step 7960: 19.670546\n",
      "Minibatch accuracy: 49.6%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 7980: 53.677586\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 8000: 31.094721\n",
      "Minibatch accuracy: 29.6%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 8020: 19.684055\n",
      "Minibatch accuracy: 49.7%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 8040: 53.676926\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 8060: 30.435678\n",
      "Minibatch accuracy: 30.4%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 8080: 19.550533\n",
      "Minibatch accuracy: 50.2%\n",
      "Validation accuracy: 61.0%\n",
      "Minibatch loss at step 8100: 53.560749\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 8120: 31.095528\n",
      "Minibatch accuracy: 28.7%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 8140: 19.476130\n",
      "Minibatch accuracy: 49.6%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 8160: 53.376842\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 8180: 31.845432\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 57.6%\n",
      "Minibatch loss at step 8200: 19.438398\n",
      "Minibatch accuracy: 49.6%\n",
      "Validation accuracy: 61.1%\n",
      "Minibatch loss at step 8220: 53.197880\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 8240: 31.149765\n",
      "Minibatch accuracy: 28.7%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 8260: 19.737875\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 59.2%\n",
      "Minibatch loss at step 8280: 53.157139\n",
      "Minibatch accuracy: 12.8%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 8300: 32.228798\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 8320: 19.910719\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8340: 52.999680\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 8360: 31.830853\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 58.0%\n",
      "Minibatch loss at step 8380: 19.881458\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8400: 52.906258\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.7%\n",
      "Minibatch loss at step 8420: 31.843164\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 8440: 19.828358\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 8460: 52.817509\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.7%\n",
      "Minibatch loss at step 8480: 31.787451\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 8500: 19.839476\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8520: 52.695694\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 8540: 31.793875\n",
      "Minibatch accuracy: 27.4%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8560: 19.825441\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8580: 52.641674\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 8600: 31.716835\n",
      "Minibatch accuracy: 27.9%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8620: 19.826530\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8640: 52.590343\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 8660: 31.628374\n",
      "Minibatch accuracy: 27.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8680: 19.837152\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 8700: 52.505756\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 8720: 31.566879\n",
      "Minibatch accuracy: 27.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8740: 19.824619\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8760: 52.409962\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.0%\n",
      "Minibatch loss at step 8780: 31.483242\n",
      "Minibatch accuracy: 27.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8800: 19.819534\n",
      "Minibatch accuracy: 46.6%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8820: 52.291321\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.0%\n",
      "Minibatch loss at step 8840: 31.303877\n",
      "Minibatch accuracy: 27.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 8860: 19.782253\n",
      "Minibatch accuracy: 47.0%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 8880: 52.112301\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 8900: 30.301899\n",
      "Minibatch accuracy: 29.2%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 8920: 19.734911\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 59.0%\n",
      "Minibatch loss at step 8940: 51.899971\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 8960: 29.269226\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 8980: 19.653715\n",
      "Minibatch accuracy: 47.3%\n",
      "Validation accuracy: 59.3%\n",
      "Minibatch loss at step 9000: 51.693680\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.7%\n",
      "Minibatch loss at step 9020: 28.815472\n",
      "Minibatch accuracy: 31.3%\n",
      "Validation accuracy: 58.2%\n",
      "Minibatch loss at step 9040: 19.595823\n",
      "Minibatch accuracy: 47.3%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 9060: 51.347496\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 9080: 28.495035\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 58.4%\n",
      "Minibatch loss at step 9100: 19.518528\n",
      "Minibatch accuracy: 47.3%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 9120: 51.240955\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 9140: 28.040844\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 9160: 19.412449\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 9180: 51.159603\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 9200: 27.446743\n",
      "Minibatch accuracy: 34.5%\n",
      "Validation accuracy: 59.0%\n",
      "Minibatch loss at step 9220: 19.264458\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 59.7%\n",
      "Minibatch loss at step 9240: 51.145073\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.6%\n",
      "Minibatch loss at step 9260: 27.188396\n",
      "Minibatch accuracy: 34.9%\n",
      "Validation accuracy: 59.2%\n",
      "Minibatch loss at step 9280: 19.284433\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 59.7%\n",
      "Minibatch loss at step 9300: 51.162476\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 9320: 27.137537\n",
      "Minibatch accuracy: 34.5%\n",
      "Validation accuracy: 59.1%\n",
      "Minibatch loss at step 9340: 19.251707\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 59.7%\n",
      "Minibatch loss at step 9360: 50.663601\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 9380: 27.808119\n",
      "Minibatch accuracy: 32.9%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 9400: 18.684769\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 61.7%\n",
      "Minibatch loss at step 9420: 50.521343\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.5%\n",
      "Minibatch loss at step 9440: 27.906805\n",
      "Minibatch accuracy: 32.1%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 9460: 18.705359\n",
      "Minibatch accuracy: 48.7%\n",
      "Validation accuracy: 61.2%\n",
      "Minibatch loss at step 9480: 50.688278\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 9500: 27.815460\n",
      "Minibatch accuracy: 32.9%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 9520: 18.798765\n",
      "Minibatch accuracy: 48.8%\n",
      "Validation accuracy: 60.6%\n",
      "Minibatch loss at step 9540: 50.344437\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.6%\n",
      "Minibatch loss at step 9560: 27.947237\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 58.7%\n",
      "Minibatch loss at step 9580: 18.868624\n",
      "Minibatch accuracy: 48.5%\n",
      "Validation accuracy: 60.2%\n",
      "Minibatch loss at step 9600: 50.465813\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 9620: 28.138954\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 9640: 18.868418\n",
      "Minibatch accuracy: 48.2%\n",
      "Validation accuracy: 60.1%\n",
      "Minibatch loss at step 9660: 50.481243\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.0%\n",
      "Minibatch loss at step 9680: 28.138020\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 9700: 18.819025\n",
      "Minibatch accuracy: 48.2%\n",
      "Validation accuracy: 60.2%\n",
      "Minibatch loss at step 9720: 50.335510\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.0%\n",
      "Minibatch loss at step 9740: 28.246790\n",
      "Minibatch accuracy: 30.8%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 9760: 18.779715\n",
      "Minibatch accuracy: 48.2%\n",
      "Validation accuracy: 60.2%\n",
      "Minibatch loss at step 9780: 49.269539\n",
      "Minibatch accuracy: 13.7%\n",
      "Validation accuracy: 61.2%\n",
      "Minibatch loss at step 9800: 28.380196\n",
      "Minibatch accuracy: 30.4%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 9820: 18.280035\n",
      "Minibatch accuracy: 49.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 9840: 50.851696\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.5%\n",
      "Minibatch loss at step 9860: 28.215858\n",
      "Minibatch accuracy: 30.4%\n",
      "Validation accuracy: 58.3%\n",
      "Minibatch loss at step 9880: 18.194935\n",
      "Minibatch accuracy: 49.6%\n",
      "Validation accuracy: 62.2%\n",
      "Minibatch loss at step 9900: 51.532013\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 63.6%\n",
      "Minibatch loss at step 9920: 27.240532\n",
      "Minibatch accuracy: 32.9%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 9940: 18.037527\n",
      "Minibatch accuracy: 50.1%\n",
      "Validation accuracy: 62.5%\n",
      "Minibatch loss at step 9960: 50.666851\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 62.8%\n",
      "Minibatch loss at step 9980: 28.173574\n",
      "Minibatch accuracy: 30.0%\n",
      "Validation accuracy: 58.1%\n",
      "Test accuracy: 52.8%\n"
     ]
    }
   ],
   "source": [
    "num_step=10000\n",
    "#def accuracy(predictions, labels):\n",
    "#  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "#          / predictions.shape[0])\n",
    "def accuracy(predictions, labels):\n",
    "    pre=np.argmax(predictions, 1.)\n",
    "    lab=np.argmax(labels, 1.)\n",
    "    #print pre[:100]\n",
    "    #print lab[:100]\n",
    "    posi=np.sum(pre*lab).astype(np.float32)/np.sum(lab).astype(np.float32)\n",
    "    #print np.sum(pre*lab)\n",
    "    #print posi\n",
    "    neg=np.sum((1.-pre)*(1.-lab)).astype(np.float32)/np.sum(1-lab).astype(np.float32)\n",
    "    #print neg\n",
    "    return 100.*2.*posi*neg/(posi+neg)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for i in range(num_step):\n",
    "        offset=i*batch_size % train_num\n",
    "        train_set_feed=train_set[offset:offset+batch_size,:]\n",
    "        train_lable_feed=train_lable[offset:offset+batch_size]\n",
    "        feed_dict={train_set_batch:train_set_feed, train_lable_batch:train_lable_feed}\n",
    "        _,l,pred=session.run([optimizer,loss,train_pred],feed_dict=feed_dict)\n",
    "        if (i % 20)==0:\n",
    "            print(\"Minibatch loss at step %d: %f\" % (i, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(pred, train_lable_feed))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_pred.eval(), valid_lable))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_pred.eval(), test_lable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 51)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
